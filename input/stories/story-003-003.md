---
id: story-003-003
epic: epic-003
title: Implement Comment Deduplication Logic for AI Analysis
priority: high
story_points: [TBD]
source_requirements: [PIPE-015, FR-038]
dependencies: [epic-002]
blocks: [story-003-004]
---

# Story: Implement Comment Deduplication Logic for AI Analysis

## Description
Query the database for existing comments by reddit_id before making AI API calls. If a comment already exists with stored annotations, skip the AI call entirely, UPDATE the analysis_run_id to the current run, and reuse stored annotations. This prevents redundant OpenAI API costs on pipeline re-runs where ~60-80% of comments may already be processed.

## Acceptance Criteria
- [ ] Before each AI API call, query the comments table by reddit_id to check for an existing record with non-null AI annotations (sentiment, sarcasm_detected, has_reasoning, confidence)
- [ ] If the comment exists with annotations: skip the AI call, UPDATE the comment's analysis_run_id to the current run ID, and return the existing annotations for downstream use in Phase 4 (signal detection)
- [ ] If the comment exists but has null annotations (edge case: previously stored but AI failed): proceed with AI analysis as if the comment were new
- [ ] If the comment does not exist: proceed to AI analysis (new comment)
- [ ] Deduplicated comments retain their original author_trust_score snapshot from first analysis (no re-lookup per PRD design note)
- [ ] The deduplication check is performed before the comment enters the ThreadPoolExecutor batch (story-003-004), not inside the concurrent worker

## Technical Notes
- The deduplication decision (whether to skip the AI call) is made exclusively in this story (Phase 3). Phase 2 (story-002-008) handles INSERT/UPDATE of comment records but does not gate AI calls.
- This dedup check is the Phase 3 complement to the Phase 2 dedup in story-002-008; both check reddit_id but this one specifically gates the AI API call
- On re-runs, deduplication saves ~60-80% of AI costs ($27-36/month savings at $45/month baseline)
- The analysis_run_id UPDATE ensures that deduplicated comments appear in Phase 4 signal detection queries (WHERE analysis_run_id = current_run)
- Batch the dedup query: SELECT all reddit_ids for the current batch in one query rather than N individual queries
- PRD reference: Section 3.2.2 Phase 3 step 1, PIPE-015

## Dependencies
- Depends on: epic-002 (comments stored in database from Reddit pipeline)
- Blocks: story-003-004 (concurrent batching processes only non-deduplicated comments)
