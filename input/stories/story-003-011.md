---
id: story-003-011
epic: epic-003
title: Write AI Parsing and Deduplication Unit Tests
priority: medium
story_points: [TBD]
source_requirements: [PIPE-018, PIPE-015, AI-RESPONSE-FORMAT, AI-TICKER-RULES]
dependencies: [story-003-009]
blocks: []
---

# Story: Write AI Parsing and Deduplication Unit Tests

## Description
Write unit tests covering AI response parsing edge cases, ticker normalization, confidence clamping, and Phase 3 deduplication logic. These tests fill the coverage gap identified in QA review: epic-003 previously had only 3 concurrency tests (story-003-010) but no tests for the parsing and dedup paths that handle the majority of AI pipeline edge cases.

## Acceptance Criteria
- [ ] Test 1 (malformed JSON): AI returns unparseable text (not JSON); verify the response is flagged for retry (story-003-006), not silently dropped
- [ ] Test 2 (extra fields in JSON): AI returns the 7 expected fields plus 2 unexpected fields; verify extra fields are ignored and parsing succeeds
- [ ] Test 3 (missing required fields): AI returns JSON missing the `sentiment` field; verify a validation error is raised and the comment is logged as skipped
- [ ] Test 4 (confidence clamping): AI returns confidence=1.5; verify it is clamped to 1.0 and a debug log is emitted. Repeat for confidence=-0.2 clamped to 0.0
- [ ] Test 5 (ticker normalization): verify "nvda" -> "NVDA", "the mouse" -> "DIS", "Zuck" -> "META"; verify excluded words ("I", "A", "CEO", "DD") are filtered out; verify deduplication within a single response ("NVDA" appearing twice -> one entry)
- [ ] Test 6 (dedup - existing with annotations): comment with reddit_id already in DB with non-null AI annotations; verify AI call is skipped, analysis_run_id is updated, existing annotations are returned
- [ ] Test 7 (dedup - existing without annotations): comment with reddit_id in DB but null sentiment; verify AI call proceeds as if the comment were new
- [ ] Test 8 (dedup - new comment): comment not in DB; verify AI call proceeds normally
- [ ] All tests use mocked OpenAI API responses and mocked database; no network access required
- [ ] Tests run with pytest and complete in under 5 seconds

## Technical Notes
- Use hand-crafted fixtures per project conventions (not VCR.py; these are unit tests)
- Ticker normalization tests should use pytest parametrize for concise coverage of many cases
- Dedup tests should mock the database query (SELECT by reddit_id) to return appropriate existing/missing records
- Confidence clamping test should verify the debug log message using structlog test utilities or caplog
- These tests complement story-003-010 (concurrency tests) to provide comprehensive epic-003 coverage
- PRD reference: PIPE-018 (response parsing), PIPE-015 (deduplication), AI-RESPONSE-FORMAT, AI-TICKER-RULES

## Dependencies
- Depends on: story-003-009 (ticker junction population must be implemented; all parsing/dedup code must exist)
- Blocks: none
