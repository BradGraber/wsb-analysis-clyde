---
id: story-006-020
epic: epic-006
title: Write Prediction Monitoring Unit Tests
priority: medium
story_points: [TBD]
source_requirements: [PIPE-058]
dependencies: [story-006-019]
blocks: []
---

# Story: Write Prediction Monitoring Unit Tests

## Description
Write 7 unit tests covering the core prediction monitoring functionality: expiration protection, stop-loss, take-profit with partial exit, trailing stop after partial, time stop, peak tracking on predictions, and verification that predictions do not impact portfolio cash.

## Acceptance Criteria
- [ ] Test 1: Prediction expiration protection triggers at DTE <= 2, resolves prediction with exit_reason='expiration'
- [ ] Test 2: Prediction stop-loss triggers when current_premium <= entry_premium * 0.50, resolves with exit_reason='stop_loss'
- [ ] Test 3: Prediction take-profit triggers at +100% premium, exits 50% contracts, sets trailing_stop_active
- [ ] Test 4: Prediction trailing stop triggers at peak_premium * 0.70 after partial take-profit, resolves prediction
- [ ] Test 5: Prediction time stop triggers at hold_days >= 10, resolves with exit_reason='time_stop'
- [ ] Test 6: Peak tracking correctly updates prediction's peak_premium after each monitoring check
- [ ] Test 7: No-cash-impact verification -- portfolio cash_available remains unchanged after prediction exit processing

## Technical Notes
- All tests use fixture/mock prediction data satisfying the MonitoredInstrument protocol.
- Test 7 is critical: asserts that portfolio cash is identical before and after prediction processing.
- Tests verify that prediction_exits records are created (not position_exits).
- Tests verify simulated_return_pct calculation: SUM(prediction_exits.simulated_pnl) / (entry_premium * contracts * 100).
- Use pytest with mock predictions, mock Schwab premium responses, and in-memory SQLite for database assertions.

## Dependencies
- Depends on: story-006-019 (prediction monitoring implementation)
- Blocks: none
